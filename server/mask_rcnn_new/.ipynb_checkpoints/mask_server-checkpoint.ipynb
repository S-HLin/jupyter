{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import log\n",
    "from mrcnn import visualize\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "sess =  tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "from flask import Flask, request, make_response\n",
    "import base64\n",
    "import cv2\n",
    "\n",
    "DEVICE = \"gpu:0\" \n",
    "weights_path = \\\n",
    "'/dataDisk/myfloder/h5/maskrcnn_snapshots/food20200605T1539/mask_rcnn_food_9500.h5'\n",
    "MODEL_DIR = '/dataDisk/myfloder/h5/maskrcnn_snapshots/'\n",
    "\n",
    "class_names = ['BG', '炸排骨', '炒青菜', '辣椒', '杏鮑菇', '蛋', '紅蘿蔔', '炸雞排', '豆腐', '木耳', '花椰菜', '筍絲', '白飯', '青椒', '小黃瓜', '炸雞腿', '玉米', '海帶', '醃蘿蔔', '黑輪', '滷排骨', '香腸', '滷蛋', '醬瓜', '豆干', '瓜仔肉', '酸菜', '雞肉', '雞腿', '浦燒魚', '地瓜', '檸檬', \n",
    "     '蟹肉條', '黑豆', '櫻桃', '玉米筍', '青豆仁', '魚板', '炸豬排', '煎魚', '香菇', '甜豆', '炸蝦', '蟹肉棒', '蝦', '燒肉', '芹菜', '彩椒', '烤雞腿', '茄子', '筍干', '爌肉', '櫻花蝦', '豬腳', '蔥', '三色蛋', '甜椒', '魚', '肉鬆', '番茄', '滷牛腱', '火腿', '炸魚排', '蒸蛋', '豆芽菜', \n",
    "     '洋芋', '豆皮', '滷雞腿', '洋蔥', '培根', '吻仔魚', '虱目魚', '蝦仁', '鴻喜菇', '炸魚', '菜脯', '苦瓜', '炸雞塊', '冬粉', '肉丸子', '煎鮭魚', '山藥捲', '絲瓜', '酸梅', '筍乾', '麵筋', '四季豆', '炸甜不辣', '花枝排', '麵腸', '九層塔', '大黃瓜', '烤鴨', '白蘿蔔', '麵輪', '叉燒', '油雞', \n",
    "     '甜不辣', '烤雞', '煎雞腿', '碗豆', '荸薺', '豬肉', '韭菜', '炸捲', '豆棗', '南瓜', '鹹瓜', '炸雞', '烤鴨腿', '菜脯蛋', '滷肉', '炸蝦捲', '筊白筍', '花枝丸', '花枝', '金針菇', '鳳梨', '蘑菇', '紅燒肉', '章魚', '煎魚排', '丸子', '地瓜球', '鹹鴨蛋', '叉燒肉', '羊排', '小卷', '牛排', \n",
    "     '柴魚', '薑', '鯖魚', '雪菜', '毛豆', '煎雞肉', '紫甘藍']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"food\"\n",
    "    \n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    \n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 135  # Background + balloon\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# def load_model():\n",
    "# global model\n",
    "# global sess\n",
    "\n",
    "cfg = InferenceConfig()\n",
    "# Create model in inference mode\n",
    "\n",
    "with tf.device(DEVICE):    \n",
    "    model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                              model_dir=MODEL_DIR,\n",
    "                              config=cfg)\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "model.keras_model._make_predict_function()\n",
    "# graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rois(r,image):\n",
    "    n=1   \n",
    "    rois=r['rois']\n",
    "    plt.figure(1,figsize=(20,20)) \n",
    "      \n",
    "    for reg in rois:\n",
    "        # print(type(image))\n",
    "        cropimg = image[reg[0]:reg[2], reg[1]:reg[3], :]\n",
    "    #     print(type(cropimg))\n",
    "#         plt.figure(1,figsize=(15,5))\n",
    "        plt.subplot(math.ceil(len(rois)/5), 5, n)\n",
    "        \n",
    "        plt.imshow(cropimg)\n",
    "    #     plt.show()\n",
    "        n+=1\n",
    "              \n",
    "def calarea(r):\n",
    "    masks = r['masks']\n",
    "    ids = r['class_ids']\n",
    "    print('mask number: {}'.format(np.shape(masks)[2]))\n",
    "    areas={}\n",
    "\n",
    "    for iid in set(ids):\n",
    "        area=0\n",
    "        for i in range(np.shape(masks)[2]): \n",
    "            if ids[i] == iid:\n",
    "                area = area + np.sum(masks[:,:,i])\n",
    "\n",
    "        #     mask = np.reshape(mask > .5, (-1, 1)).astype(np.float32)\n",
    "        #     area = np.sum(mask, axis= 0) #計算mask_面積\n",
    "        print('mask_area= %d  class_id=%s'%(area,class_names[iid]))\n",
    "        areas[iid] = area\n",
    "\n",
    "    r['areas']= areas       \n",
    "\n",
    "def imgdetect(img_base64): \n",
    "    global sess\n",
    "    global graph\n",
    "    \n",
    "    img_data = base64.b64decode(img_base64)\n",
    "#     img_array = np.fromstring(img_data, np.uint8)\n",
    "    img_array = np.frombuffer(img_data, np.uint8)\n",
    "    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if image.shape[-1] == 4:    \n",
    "        image = image[...,:3]\n",
    "    \n",
    "    # Run detection\n",
    "    with graph.as_default():\n",
    "        set_session(sess)\n",
    "        results = model.detect([image], verbose=1)\n",
    "\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    visualize.display_instances(image, \n",
    "                                r['rois'], \n",
    "                                r['masks'], \n",
    "                                r['class_ids'], \n",
    "                                class_names, \n",
    "                                r['scores'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://140.116.67.155:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (740, 540, 3)         min:    9.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 148)              min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-06-18 14:17:57,901] ERROR in app: Exception on / [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1356, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1339, in _run_fn\n",
      "    self._extend_graph()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1374, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation ROI/rpn_non_max_suppression/NonMaxSuppressionV3: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU] possible_devices_=[]\n",
      "NonMaxSuppressionV3: CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  ROI/rpn_non_max_suppression/NonMaxSuppressionV3 (NonMaxSuppressionV3) /device:GPU:0\n",
      "\n",
      "Op: NonMaxSuppressionV3\n",
      "Node attrs: T=DT_FLOAT\n",
      "Registered kernels:\n",
      "  device='CPU'; T in [DT_HALF]\n",
      "  device='CPU'; T in [DT_FLOAT]\n",
      "\n",
      "\t [[{{node ROI/rpn_non_max_suppression/NonMaxSuppressionV3}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/flask/app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/flask/_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/flask/app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-5-e43452ef1fe4>\", line 15, in get_request\n",
      "    imgdetect(img_base64)\n",
      "  File \"<ipython-input-4-784a0fc65042>\", line 51, in imgdetect\n",
      "    results = model.detect([image], verbose=1)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/model.py\", line 2502, in detect\n",
      "    self.keras_model.predict([molded_images, image_metas, anchors], verbose=0)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 1456, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\", line 378, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3006, in function\n",
      "    v1_variable_initialization()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 420, in v1_variable_initialization\n",
      "    session = get_session()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 385, in get_session\n",
      "    return tf_keras_backend.get_session()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 462, in get_session\n",
      "    _initialize_variables(session)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 879, in _initialize_variables\n",
      "    [variables_module.is_variable_initialized(v) for v in candidate_vars])\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 950, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1173, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1370, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation ROI/rpn_non_max_suppression/NonMaxSuppressionV3: Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\n",
      "Colocation Debug Info:\n",
      "Colocation group had the following types and supported devices: \n",
      "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU] possible_devices_=[]\n",
      "NonMaxSuppressionV3: CPU \n",
      "\n",
      "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
      "  ROI/rpn_non_max_suppression/NonMaxSuppressionV3 (NonMaxSuppressionV3) /device:GPU:0\n",
      "\n",
      "Op: NonMaxSuppressionV3\n",
      "Node attrs: T=DT_FLOAT\n",
      "Registered kernels:\n",
      "  device='CPU'; T in [DT_HALF]\n",
      "  device='CPU'; T in [DT_FLOAT]\n",
      "\n",
      "\t [[node ROI/rpn_non_max_suppression/NonMaxSuppressionV3 (defined at /home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/model.py:321) ]]\n",
      "\n",
      "Errors may have originated from an input operation.\n",
      "Input Source operations connected to node ROI/rpn_non_max_suppression/NonMaxSuppressionV3:\n",
      " ROI/strided_slice_21 (defined at /home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/utils.py:828)\n",
      "\n",
      "Original stack trace for 'ROI/rpn_non_max_suppression/NonMaxSuppressionV3':\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 597, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-55f217974f55>\", line 12, in <module>\n",
      "    config=cfg)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/model.py\", line 1832, in __init__\n",
      "    self.keras_model = self.build(mode=mode, config=config)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/model.py\", line 1960, in build\n",
      "    config=config)([rpn_class, rpn_bbox, anchors])\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 489, in __call__\n",
      "    output = self.call(inputs, **kwargs)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/model.py\", line 328, in call\n",
      "    self.config.IMAGES_PER_GPU)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/utils.py\", line 829, in batch_slice\n",
      "    output_slice = graph_fn(*inputs_slice)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/mrcnn/model.py\", line 321, in nms\n",
      "    self.nms_threshold, name=\"rpn_non_max_suppression\")\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/image_ops_impl.py\", line 2587, in non_max_suppression\n",
      "    iou_threshold, score_threshold)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_image_ops.py\", line 2450, in non_max_suppression_v3\n",
      "    score_threshold=score_threshold, name=name)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/user/miniconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140.116.67.155 - - [18/Jun/2020 14:17:57] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "# from flask import Flask, request, make_response\n",
    "# import base64\n",
    "# import cv2\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def get_request():\n",
    "    if request.method == 'POST':\n",
    "        content = request.get_json()\n",
    "#         img_data = base64.b64decode(content['photo']) \n",
    "#         img_array = np.fromstring(img_data, np.uint8)\n",
    "#         img = cv2.imdecode(img_array, cv2.IMREAD_COLOR) \n",
    "        img_base64 = content['photo']\n",
    "        imgdetect(img_base64)\n",
    "        \n",
    "#         response = make_response(img_data)\n",
    "#         response.headers['Content-Type'] = 'image/jpg'\n",
    "\n",
    "#         return response\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='140.116.67.155', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = request.get_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, make_response\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import time\n",
    "import base64\n",
    "import cv2\n",
    " \n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/img/<string:filename>', methods=['POST', 'GET'])\n",
    "def display_img(filename):\n",
    "    request_begin_time = datetime.today()\n",
    "    print(\"request_begin_time\", request_begin_time)\n",
    "    \n",
    "    if request.method == 'POST':       \n",
    "        content = request.get_json()\n",
    "        \n",
    "        img_data = base64.b64decode(content['photo'])\n",
    "        img_array = np.fromstring(img_data, np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR) \n",
    "        \n",
    "        filename = time.strftime('%Y%m%d%H%M')\n",
    "        print(filename)\n",
    "      \n",
    "        response = make_response(img)\n",
    "#         response.headers['Content-Type'] = 'image/jpg'\n",
    "        return url_for('display_img',filename=filename)\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='140.116.67.155', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, make_response\n",
    "from datetime import datetime\n",
    "import os\n",
    " \n",
    "app = Flask(__name__)\n",
    "IMG_PATH = \"./img/\"\n",
    " \n",
    " \n",
    "@app.route('/display/img/<string:filename>', methods=['GET'])\n",
    "def display_img(filename):\n",
    "    request_begin_time = datetime.today()\n",
    "    print(\"request_begin_time\", request_begin_time)\n",
    "    if request.method == 'GET':\n",
    "        if filename is None:\n",
    "            pass\n",
    "        else:\n",
    "            image_data = open(IMG_PATH + filename, \"rb\").read()\n",
    "            print(type(image_data))\n",
    "            response = make_response(image_data)\n",
    "            response.headers['Content-Type'] = 'image/jpg'\n",
    "            return response\n",
    "    else:\n",
    "        pass\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, make_response,jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    " \n",
    "from datetime import timedelta\n",
    " \n",
    "#设置允许的文件格式\n",
    "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'JPG', 'PNG', 'bmp'])\n",
    " \n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1] in ALLOWED_EXTENSIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "# 设置静态文件缓存过期时间\n",
    "app.send_file_max_age_default = timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/upload', methods=['POST', 'GET'])\n",
    "@app.route('/upload', methods=['POST', 'GET'])  # 添加路由\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        if not (f and allowed_file(f.filename)):\n",
    "            return jsonify({\"error\": 1001, \"msg\": \"请检查上传的图片类型，仅限于png、PNG、jpg、JPG、bmp\"})\n",
    "        \n",
    "        user_input = request.form.get(\"name\")\n",
    "        \n",
    "        basepath = os.path.dirname(__file__)  # 当前文件所在路径\n",
    "        \n",
    "        upload_path = os.path.join(basepath, 'static/images', secure_filename(f.filename))  # 注意：没有的文件夹一定要先创建，不然会提示没有该路径\n",
    "        # upload_path = os.path.join(basepath, 'static/images','test.jpg')  #注意：没有的文件夹一定要先创建，不然会提示没有该路径\n",
    "        f.save(upload_path)\n",
    "        \n",
    "        # 使用Opencv转换一下图片格式和名称\n",
    "        img = cv2.imread(upload_path)\n",
    "        cv2.imwrite(os.path.join(basepath, 'static/images', 'test.jpg'), img)\n",
    "        \n",
    "        return render_template('upload_ok.html',userinput=user_input,val1=time.time())\n",
    "    \n",
    "    return render_template('upload.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # app.debug = True\n",
    "    app.run(host='0.0.0.0', port=8987, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = base64.b64decode(base64_code)\n",
    "img_array = np.fromstring(img_data, np.uint8)\n",
    "img = cv2.imdecode(img_array, cv2.IMREAD_COLOR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    return \"Hello Flask!\"\n",
    "\n",
    "@app.route(\"/apple\")\n",
    "def apple():\n",
    "    return \"I am apple!\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/upload', methods=['POST', 'GET'])\n",
    "@app.route('/upload', methods=['POST', 'GET'])  # 添加路由\n",
    "def upload():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        if not (f and allowed_file(f.filename)):\n",
    "            return jsonify({\"error\": 1001, \"msg\": \"请检查上传的图片类型，仅限于png、PNG、jpg、JPG、bmp\"})\n",
    "        \n",
    "        user_input = request.form.get(\"name\")\n",
    "        \n",
    "        basepath = os.path.dirname(__file__)  # 当前文件所在路径\n",
    "        \n",
    "        upload_path = os.path.join(basepath, 'static/images', secure_filename(f.filename))  # 注意：没有的文件夹一定要先创建，不然会提示没有该路径\n",
    "        # upload_path = os.path.join(basepath, 'static/images','test.jpg')  #注意：没有的文件夹一定要先创建，不然会提示没有该路径\n",
    "        f.save(upload_path)\n",
    "        \n",
    "        # 使用Opencv转换一下图片格式和名称\n",
    "        img = cv2.imread(upload_path)\n",
    "        cv2.imwrite(os.path.join(basepath, 'static/images', 'test.jpg'), img)\n",
    "        \n",
    "        return render_template('upload_ok.html',userinput=user_input,val1=time.time())\n",
    "    \n",
    "    return render_template('upload.html')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "392.656px",
    "left": "947.853px",
    "right": "20px",
    "top": "176.993px",
    "width": "308.233px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
